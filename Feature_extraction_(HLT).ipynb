{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP+Y7KWlw855KXKt8qCHJDW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fi-co/Distinguishing-AI-Generated-and-Human-Written-Scientific-Texts-/blob/main/Feature_extraction_(HLT).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Libraries"
      ],
      "metadata": {
        "id": "eC1rFIMfHO17"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "akN8ZrABlTVh"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MODEL**"
      ],
      "metadata": {
        "id": "wi4Zd-NfHKtc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Initialize feature extraction function\n",
        "\n",
        "def extract_features(df):\n",
        "    features = pd.DataFrame()\n",
        "\n",
        "    def sentence_lengths(text):\n",
        "        sentences = re.split(r'[.!?]', text)\n",
        "        lengths = [len(sentence.split()) for sentence in sentences if sentence.strip()]\n",
        "        return lengths\n",
        "\n",
        "    def contains_frequent_capitals(text):\n",
        "        return len(re.findall(r'[A-Z]', text)) / max(1, text.count('.'))\n",
        "\n",
        "    def average_sentence_length(text):\n",
        "        lengths = sentence_lengths(text)\n",
        "        return np.mean(lengths) if lengths else 0\n",
        "\n",
        "    def lexical_diversity(text):\n",
        "        words = re.findall(r'\\b\\w+\\b', text.lower())\n",
        "        return len(set(words)) / len(words) if words else 0\n",
        "\n",
        "    # Define a function to count the number of words in each text\n",
        "    def word_count(text):\n",
        "        words = re.findall(r'\\b\\w+\\b', text)\n",
        "        return len(words)\n",
        "\n",
        "   # Feature set.\n",
        "   # Those commented were found not discriminating. For transparency, I retained them.\n",
        "\n",
        "    features['sentences_per_paragraph'] = df['Text'].apply(lambda x: len(re.split(r'[.!?]', x)) - 1)\n",
        "\n",
        "    features['sentence_length_std'] = df['Text'].apply(lambda x: np.std(sentence_lengths(x)) if len(sentence_lengths(x)) > 1 else 0)\n",
        "\n",
        "    #features['repetitive_paragraph_structure'] = df['Text'].apply(lambda x: 1 if len(set(re.split(r'[.!?]', x))) < 2 else 0)\n",
        "\n",
        "    features['word_count'] = df['Text'].apply(word_count)\n",
        "\n",
        "    features['average_sentence_length'] = df['Text'].apply(average_sentence_length)\n",
        "\n",
        "    features['lexical_diversity'] = df['Text'].apply(lexical_diversity)\n",
        "\n",
        "    features['contains_colon_semicolon'] = df['Text'].str.contains(r'[;:]', case=False, regex=True).astype(int)\n",
        "\n",
        "    features['contains_question_mark'] = df['Text'].str.contains(r'\\?', case=False, regex=True).astype(int)\n",
        "\n",
        "    features['contains_apostrophe'] = df['Text'].str.contains(r\"'\", case=False, regex=True).astype(int)\n",
        "\n",
        "    #features['sentence_length_uniformity'] = df['Text'].apply(lambda x: 1 if len(set(sentence_lengths(x))) == 1 else 0)\n",
        "\n",
        "    #features['repetitive_sentence_structures'] = df['Text'].apply(lambda x: repetitive_structure(sentence_lengths(x)))\n",
        "\n",
        "    features['contains_although'] = df['Text'].str.contains(r'\\balthough\\b', case=False, regex=True).astype(int)\n",
        "\n",
        "    features['contains_connectors'] = df['Text'].apply(lambda x: int(any(connector in x.lower() for connector in ['also', 'in addition'])))\n",
        "\n",
        "    features['contains_however'] = df['Text'].str.contains(r'\\bhowever\\b', case=False, regex=True).astype(int)\n",
        "\n",
        "    features['contains_others_researchers'] = df['Text'].str.contains(r'\\bothers\\b|\\bresearchers\\b', case=False, regex=True).astype(int)\n",
        "\n",
        "    features['contains_numbers'] = df['Text'].str.contains(r'\\d', case=False, regex=True).astype(int)\n",
        "\n",
        "    features['contains_delve'] = df['Text'].str.contains(r'\\b(delve|delves)\\b', case=False, regex=True).astype(int)\n",
        "\n",
        "    features['capitals_to_periods_ratio'] = df['Text'].apply(lambda x: contains_frequent_capitals(x))\n",
        "\n",
        "    features['contains_et'] = df['Text'].str.contains(r'\\bet\\b', case=False, regex=True).astype(int)\n",
        "\n",
        "    return features"
      ],
      "metadata": {
        "id": "zH3u91vOllqC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load data from two CSV files with correct delimiters\n",
        "\n",
        "df_human = pd.read_csv('file_name', delimiter=';')\n",
        "df_ai = pd.read_csv('file_name', delimiter=';')\n",
        "\n",
        "\n",
        "# Ensure labels are in the DataFrames (assume column name is 'Label')\n",
        "# If the label column has a different name, replace 'Label' with the correct name.\n",
        "\n",
        "assert 'Label' in df_human.columns, \"Label column missing in human.csv\"\n",
        "assert 'Label' in df_ai.columns, \"Label column missing in ai.csv\"\n",
        "\n",
        "# Check structure of the loaded data\n",
        "#print(df_human.head())\n",
        "#print(df_ai.head())\n",
        "\n",
        "# Concatenate the dataframes\n",
        "\n",
        "df = pd.concat([df_human, df_ai], ignore_index=True)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ftOmkf7yJe6C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Separate the labels from the text\n",
        "\n",
        "labels = df['Label']\n",
        "texts = df['Text']\n",
        "\n",
        "\n",
        "# Create a new DataFrame with the text for feature extraction\n",
        "\n",
        "feature_df = pd.DataFrame({'Text': texts})\n",
        "\n",
        "\n",
        "# Extract features\n",
        "\n",
        "X = extract_features(feature_df)\n",
        "\n",
        "\n",
        "# Combine features and labels into a final dataset\n",
        "\n",
        "feature_map = pd.concat([X, labels.reset_index(drop=True)], axis=1)\n",
        "\n",
        "# Save features to a new csv file\n",
        "feature_map.to_csv('features.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "6W43p7cZKGUJ",
        "outputId": "5a4f152c-b725-4e66-e4d9-e9c3ebf6e391"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-6b806744cce4>:60: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
            "  features['contains_delve'] = df['Text'].str.contains(r'\\b(delve|delves)\\b', case=False, regex=True).astype(int)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "variance analysis\n"
      ],
      "metadata": {
        "id": "bYJpDEG0miLG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Analyze variance\n",
        "\n",
        "feature_variance = X.var()\n",
        "print(feature_variance[feature_variance == 0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hX9q-Dh0k9UG",
        "outputId": "9a9c83bf-1c8f-4b61-a886-aba6a99201d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Series([], dtype: float64)\n"
          ]
        }
      ]
    }
  ]
}